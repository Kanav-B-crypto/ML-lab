{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4334fbc7-cfe3-4265-a743-41f7f0f9b409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Scraping page 16...\n",
      "Scraping page 17...\n",
      "Scraping page 18...\n",
      "Scraping page 19...\n",
      "Scraping page 20...\n",
      "Scraping page 21...\n",
      "Scraping page 22...\n",
      "Scraping page 23...\n",
      "Scraping page 24...\n",
      "Scraping page 25...\n",
      "Scraping page 26...\n",
      "Scraping page 27...\n",
      "Scraping page 28...\n",
      "Scraping page 29...\n",
      "Scraping page 30...\n",
      "Scraping page 31...\n",
      "Scraping page 32...\n",
      "Scraping page 33...\n",
      "Scraping page 34...\n",
      "Scraping page 35...\n",
      "Scraping page 36...\n",
      "Scraping page 37...\n",
      "Scraping page 38...\n",
      "Scraping page 39...\n",
      "Scraping page 40...\n",
      "Scraping page 41...\n",
      "Scraping page 42...\n",
      "Scraping page 43...\n",
      "Scraping page 44...\n",
      "Scraping page 45...\n",
      "Scraping page 46...\n",
      "Scraping page 47...\n",
      "Scraping page 48...\n",
      "Scraping page 49...\n",
      "Scraping page 50...\n",
      "✅ Scraping completed! Data saved to books.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Star Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>51.77</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>53.74</td>\n",
       "      <td>In stock</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>50.10</td>\n",
       "      <td>In stock</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>47.82</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>54.23</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Title  Price Availability Star Rating\n",
       "0                   A Light in the Attic  51.77     In stock       Three\n",
       "1                     Tipping the Velvet  53.74     In stock         One\n",
       "2                             Soumission  50.10     In stock         One\n",
       "3                          Sharp Objects  47.82     In stock        Four\n",
       "4  Sapiens: A Brief History of Humankind  54.23     In stock        Five"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "books_data = []\n",
    "\n",
    "for page in range(1, 51):\n",
    "    url = base_url.format(page)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    books = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "    \n",
    "    print(f\"Scraping page {page}...\")  # progress indicator\n",
    "    \n",
    "    for book in books:\n",
    "        title = book.h3.a[\"title\"]\n",
    "        \n",
    "        price = book.find(\"p\", class_=\"price_color\").text.strip()\n",
    "        price = price.replace(\"£\", \"\").replace(\"Â\", \"\").strip()\n",
    "        \n",
    "        availability = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
    "        star_rating = book.find(\"p\", class_=\"star-rating\")[\"class\"][1]\n",
    "        \n",
    "        books_data.append({\n",
    "            \"Title\": title,\n",
    "            \"Price\": float(price),\n",
    "            \"Availability\": availability,\n",
    "            \"Star Rating\": star_rating\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(books_data)\n",
    "df.to_csv(\"books.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Scraping completed! Data saved to books.csv\")\n",
    "df.head() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ef4b98-0280-4a56-9060-cc89694d7ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping completed! Data saved to imdb_top250.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1. The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.3(3.1M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2. The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2(2.2M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3. The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.1(3.1M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4. The Godfather: Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0(1.5M)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5. 12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>9.0(948K)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                        Title  Year     Rating\n",
       "0     1  1. The Shawshank Redemption  1994  9.3(3.1M)\n",
       "1     2             2. The Godfather  1972  9.2(2.2M)\n",
       "2     3           3. The Dark Knight  2008  9.1(3.1M)\n",
       "3     4    4. The Godfather: Part II  1974  9.0(1.5M)\n",
       "4     5              5. 12 Angry Men  1957  9.0(948K)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.imdb.com/chart/top/\"\n",
    "response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "movies = soup.select(\"li.ipc-metadata-list-summary-item\")\n",
    "data = []\n",
    "\n",
    "for rank, movie in enumerate(movies, start=1):\n",
    "    title = movie.find(\"h3\").get_text(strip=True)\n",
    "    year = movie.select_one(\".cli-title-metadata-item\").get_text(strip=True)\n",
    "    rating = movie.select_one(\".ipc-rating-star--imdb\").get_text(strip=True).split()[0]\n",
    "    data.append({\n",
    "        \"Rank\": rank,\n",
    "        \"Title\": title,\n",
    "        \"Year\": year,\n",
    "        \"Rating\": rating\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"imdb_top250.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Scraping completed! Data saved to imdb_top250.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74cf2262-182d-4551-bbba-9805b91de53d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m table \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzebra fw tb-wt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m rows \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# skip header row\u001b[39;00m\n\u001b[0;32m     12\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.timeanddate.com/weather/\"\n",
    "response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "table = soup.find(\"table\", class_=\"zebra fw tb-wt\")\n",
    "rows = table.find_all(\"tr\")[1:]  # skip header row\n",
    "\n",
    "data = []\n",
    "\n",
    "for row in rows:\n",
    "    cols = row.find_all(\"td\")\n",
    "    city = cols[0].get_text(strip=True)\n",
    "    temp = cols[1].get_text(strip=True)\n",
    "    condition = cols[2].get_text(strip=True)\n",
    "    \n",
    "    data.append({\n",
    "        \"City\": city,\n",
    "        \"Temperature\": temp,\n",
    "        \"Condition\": condition\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"weather.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Scraping completed! Data saved to weather.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8acf26-8b89-4695-83e5-ec6f62219b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
